{"Collections-26": [{"prefix": "     * @return true if equal\n     */\n    @Override\n    public boolean equals(final Object other) {\n        if (other == this) {\n            return true;\n        }\n        if (other instanceof MultiKey) {\n            final MultiKey<?> otherMulti = (MultiKey<?>) other;\n            return Arrays.equals(keys, otherMulti.keys);\n        }\n        return false;\n    }\n\n    /**\n     * Gets the combined hash code that is computed from all the keys.\n     * <p>\n     * This value is computed once and then cached, so elements should not\n     * change their hash codes once created (note that this is the same\n     * constraint that would be used if the individual keys elements were\n     * themselves {@link java.util.Map Map} keys.\n     *\n     * @return the hash code\n     */\n    @Override\n    public int hashCode() {\n        return hashCode;\n    }\n\n    /**\n     * Gets a debugging string version of the key.\n     *\n     * @return a debugging string\n     */\n    @Override\n    public String toString() {\n        return \"MultiKey\" + Arrays.toString(keys);\n    }\n\n    /**\n     * Calculate the hash code of the instance using the provided keys.\n     * @param keys the keys to calculate the hash code for\n     */\n    private void calculateHashCode(final Object[] keys)\n    {\n        int total = 0;\n        for (final Object key : keys) {\n            if (key != null) {\n                total ^= key.hashCode();\n            }\n        }\n        hashCode = total;\n    }\n\n    /**\n     * Recalculate the hash code after deserialization. The hash code of some\n     * keys might have change (hash codes based on the system hash code are\n     * only stable for the same process).\n     * @return the instance with recalculated hash code\n     */\n", "suffix": "        calculateHashCode(keys);\n        return this;\n    }\n}\n", "buggy": "     * @return true if equal\n     */\n    @Override\n    public boolean equals(final Object other) {\n        if (other == this) {\n            return true;\n        }\n        if (other instanceof MultiKey) {\n            final MultiKey<?> otherMulti = (MultiKey<?>) other;\n            return Arrays.equals(keys, otherMulti.keys);\n        }\n        return false;\n    }\n\n    /**\n     * Gets the combined hash code that is computed from all the keys.\n     * <p>\n     * This value is computed once and then cached, so elements should not\n     * change their hash codes once created (note that this is the same\n     * constraint that would be used if the individual keys elements were\n     * themselves {@link java.util.Map Map} keys.\n     *\n     * @return the hash code\n     */\n    @Override\n    public int hashCode() {\n        return hashCode;\n    }\n\n    /**\n     * Gets a debugging string version of the key.\n     *\n     * @return a debugging string\n     */\n    @Override\n    public String toString() {\n        return \"MultiKey\" + Arrays.toString(keys);\n    }\n\n    /**\n     * Calculate the hash code of the instance using the provided keys.\n     * @param keys the keys to calculate the hash code for\n     */\n    private void calculateHashCode(final Object[] keys)\n    {\n        int total = 0;\n        for (final Object key : keys) {\n            if (key != null) {\n                total ^= key.hashCode();\n            }\n        }\n        hashCode = total;\n    }\n\n    /**\n     * Recalculate the hash code after deserialization. The hash code of some\n     * keys might have change (hash codes based on the system hash code are\n     * only stable for the same process).\n     * @return the instance with recalculated hash code\n     */\n    private Object readResolve() {\n        calculateHashCode(keys);\n        return this;\n    }\n}\n", "fix": "     * @return true if equal\n     */\n    @Override\n    public boolean equals(final Object other) {\n        if (other == this) {\n            return true;\n        }\n        if (other instanceof MultiKey) {\n            final MultiKey<?> otherMulti = (MultiKey<?>) other;\n            return Arrays.equals(keys, otherMulti.keys);\n        }\n        return false;\n    }\n\n    /**\n     * Gets the combined hash code that is computed from all the keys.\n     * <p>\n     * This value is computed once and then cached, so elements should not\n     * change their hash codes once created (note that this is the same\n     * constraint that would be used if the individual keys elements were\n     * themselves {@link java.util.Map Map} keys.\n     *\n     * @return the hash code\n     */\n    @Override\n    public int hashCode() {\n        return hashCode;\n    }\n\n    /**\n     * Gets a debugging string version of the key.\n     *\n     * @return a debugging string\n     */\n    @Override\n    public String toString() {\n        return \"MultiKey\" + Arrays.toString(keys);\n    }\n\n    /**\n     * Calculate the hash code of the instance using the provided keys.\n     * @param keys the keys to calculate the hash code for\n     */\n    private void calculateHashCode(final Object[] keys)\n    {\n        int total = 0;\n        for (final Object key : keys) {\n            if (key != null) {\n                total ^= key.hashCode();\n            }\n        }\n        hashCode = total;\n    }\n\n    /**\n     * Recalculate the hash code after deserialization. The hash code of some\n     * keys might have change (hash codes based on the system hash code are\n     * only stable for the same process).\n     * @return the instance with recalculated hash code\n     */\n    protected Object readResolve() {\n        calculateHashCode(keys);\n        return this;\n    }\n}\n", "start": 216, "end": 336, "file": "main/java/org/apache/commons/collections4/keyvalue/MultiKey.java"}], "Compress-1": [{"prefix": "    public void finish() throws IOException {\n        ensureOpen();\n\n        if (this.finished) {\n            return;\n        }\n        if (this.cpioEntry != null) {\n            closeArchiveEntry();\n        }\n        this.cpioEntry = new CpioArchiveEntry(this.entryFormat);\n        this.cpioEntry.setMode(0);\n        this.cpioEntry.setName(\"TRAILER!!!\");\n        this.cpioEntry.setNumberOfLinks(1);\n        writeHeader(this.cpioEntry);\n        closeArchiveEntry();\n    }\n\n    /**\n     * Closes the CPIO output stream as well as the stream being filtered.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void close() throws IOException {\n        if (!this.closed) {\n", "suffix": "            super.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(final long count, final int border) throws IOException {\n        long skip = count % border;\n        if (skip > 0) {\n            byte tmp[] = new byte[(int) (border - skip)];\n            out.write(tmp);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length,\n            final boolean swapHalfWord) throws IOException {\n        byte tmp[] = CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n    }\n\n    private void writeAsciiLong(final long number, final int length,\n            final int radix) throws IOException {\n        StringBuffer tmp = new StringBuffer();\n        String tmpStr;\n        if (radix == 16) {\n            tmp.append(Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(Long.toOctalString(number));\n", "buggy": "    public void finish() throws IOException {\n        ensureOpen();\n\n        if (this.finished) {\n            return;\n        }\n        if (this.cpioEntry != null) {\n            closeArchiveEntry();\n        }\n        this.cpioEntry = new CpioArchiveEntry(this.entryFormat);\n        this.cpioEntry.setMode(0);\n        this.cpioEntry.setName(\"TRAILER!!!\");\n        this.cpioEntry.setNumberOfLinks(1);\n        writeHeader(this.cpioEntry);\n        closeArchiveEntry();\n    }\n\n    /**\n     * Closes the CPIO output stream as well as the stream being filtered.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void close() throws IOException {\n        if (!this.closed) {\n            super.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(final long count, final int border) throws IOException {\n        long skip = count % border;\n        if (skip > 0) {\n            byte tmp[] = new byte[(int) (border - skip)];\n            out.write(tmp);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length,\n            final boolean swapHalfWord) throws IOException {\n        byte tmp[] = CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n    }\n\n    private void writeAsciiLong(final long number, final int length,\n            final int radix) throws IOException {\n        StringBuffer tmp = new StringBuffer();\n        String tmpStr;\n        if (radix == 16) {\n            tmp.append(Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(Long.toOctalString(number));\n", "fix": "    public void finish() throws IOException {\n        ensureOpen();\n\n        if (this.finished) {\n            return;\n        }\n        if (this.cpioEntry != null) {\n            closeArchiveEntry();\n        }\n        this.cpioEntry = new CpioArchiveEntry(this.entryFormat);\n        this.cpioEntry.setMode(0);\n        this.cpioEntry.setName(\"TRAILER!!!\");\n        this.cpioEntry.setNumberOfLinks(1);\n        writeHeader(this.cpioEntry);\n        closeArchiveEntry();\n    }\n\n    /**\n     * Closes the CPIO output stream as well as the stream being filtered.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void close() throws IOException {\n        if (!this.closed) {\n            this.finish();\n            super.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(final long count, final int border) throws IOException {\n        long skip = count % border;\n        if (skip > 0) {\n            byte tmp[] = new byte[(int) (border - skip)];\n            out.write(tmp);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length,\n            final boolean swapHalfWord) throws IOException {\n        byte tmp[] = CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n    }\n\n    private void writeAsciiLong(final long number, final int length,\n            final int radix) throws IOException {\n        StringBuffer tmp = new StringBuffer();\n        String tmpStr;\n        if (radix == 16) {\n            tmp.append(Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(Long.toOctalString(number));\n", "start": 319, "end": 371, "file": "main/java/org/apache/commons/compress/archivers/cpio/CpioArchiveOutputStream.java"}], "Compress-19": [{"prefix": "            diskStart = new ZipLong(buffer, offset + length - WORD);\n        }\n    }\n\n    /**\n     * Parses the raw bytes read from the central directory extra\n     * field with knowledge which fields are expected to be there.\n     *\n     * <p>All four fields inside the zip64 extended information extra\n     * field are optional and must only be present if their corresponding\n     * entry inside the central directory contains the correct magic\n     * value.</p>\n     */\n    public void reparseCentralDirectoryData(boolean hasUncompressedSize,\n                                            boolean hasCompressedSize,\n                                            boolean hasRelativeHeaderOffset,\n                                            boolean hasDiskStart)\n        throws ZipException {\n        if (rawCentralDirectoryData != null) {\n            int expectedLength = (hasUncompressedSize ? DWORD : 0)\n                + (hasCompressedSize ? DWORD : 0)\n                + (hasRelativeHeaderOffset ? DWORD : 0)\n                + (hasDiskStart ? WORD : 0);\n", "suffix": "                throw new ZipException(\"central directory zip64 extended\"\n                                       + \" information extra field's length\"\n                                       + \" doesn't match central directory\"\n                                       + \" data.  Expected length \"\n                                       + expectedLength + \" but is \"\n                                       + rawCentralDirectoryData.length);\n            }\n            int offset = 0;\n            if (hasUncompressedSize) {\n                size = new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasCompressedSize) {\n                compressedSize = new ZipEightByteInteger(rawCentralDirectoryData,\n                                                         offset);\n                offset += DWORD;\n            }\n            if (hasRelativeHeaderOffset) {\n                relativeHeaderOffset =\n                    new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasDiskStart) {\n", "buggy": "            diskStart = new ZipLong(buffer, offset + length - WORD);\n        }\n    }\n\n    /**\n     * Parses the raw bytes read from the central directory extra\n     * field with knowledge which fields are expected to be there.\n     *\n     * <p>All four fields inside the zip64 extended information extra\n     * field are optional and must only be present if their corresponding\n     * entry inside the central directory contains the correct magic\n     * value.</p>\n     */\n    public void reparseCentralDirectoryData(boolean hasUncompressedSize,\n                                            boolean hasCompressedSize,\n                                            boolean hasRelativeHeaderOffset,\n                                            boolean hasDiskStart)\n        throws ZipException {\n        if (rawCentralDirectoryData != null) {\n            int expectedLength = (hasUncompressedSize ? DWORD : 0)\n                + (hasCompressedSize ? DWORD : 0)\n                + (hasRelativeHeaderOffset ? DWORD : 0)\n                + (hasDiskStart ? WORD : 0);\n            if (rawCentralDirectoryData.length != expectedLength) {\n                throw new ZipException(\"central directory zip64 extended\"\n                                       + \" information extra field's length\"\n                                       + \" doesn't match central directory\"\n                                       + \" data.  Expected length \"\n                                       + expectedLength + \" but is \"\n                                       + rawCentralDirectoryData.length);\n            }\n            int offset = 0;\n            if (hasUncompressedSize) {\n                size = new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasCompressedSize) {\n                compressedSize = new ZipEightByteInteger(rawCentralDirectoryData,\n                                                         offset);\n                offset += DWORD;\n            }\n            if (hasRelativeHeaderOffset) {\n                relativeHeaderOffset =\n                    new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasDiskStart) {\n", "fix": "            diskStart = new ZipLong(buffer, offset + length - WORD);\n        }\n    }\n\n    /**\n     * Parses the raw bytes read from the central directory extra\n     * field with knowledge which fields are expected to be there.\n     *\n     * <p>All four fields inside the zip64 extended information extra\n     * field are optional and must only be present if their corresponding\n     * entry inside the central directory contains the correct magic\n     * value.</p>\n     */\n    public void reparseCentralDirectoryData(boolean hasUncompressedSize,\n                                            boolean hasCompressedSize,\n                                            boolean hasRelativeHeaderOffset,\n                                            boolean hasDiskStart)\n        throws ZipException {\n        if (rawCentralDirectoryData != null) {\n            int expectedLength = (hasUncompressedSize ? DWORD : 0)\n                + (hasCompressedSize ? DWORD : 0)\n                + (hasRelativeHeaderOffset ? DWORD : 0)\n                + (hasDiskStart ? WORD : 0);\n            if (rawCentralDirectoryData.length < expectedLength) {\n                throw new ZipException(\"central directory zip64 extended\"\n                                       + \" information extra field's length\"\n                                       + \" doesn't match central directory\"\n                                       + \" data.  Expected length \"\n                                       + expectedLength + \" but is \"\n                                       + rawCentralDirectoryData.length);\n            }\n            int offset = 0;\n            if (hasUncompressedSize) {\n                size = new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasCompressedSize) {\n                compressedSize = new ZipEightByteInteger(rawCentralDirectoryData,\n                                                         offset);\n                offset += DWORD;\n            }\n            if (hasRelativeHeaderOffset) {\n                relativeHeaderOffset =\n                    new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasDiskStart) {\n", "start": 235, "end": 281, "file": "main/java/org/apache/commons/compress/archivers/zip/Zip64ExtendedInformationExtraField.java"}], "Compress-23": [{"prefix": "                byte[] password) throws IOException;\n        OutputStream encode(final OutputStream out, final byte[] password)\n            throws IOException {\n            throw new UnsupportedOperationException(\"method doesn't support writing\");\n        }\n    }\n    \n    static class CopyDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            return in; \n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return out;\n        }\n    }\n\n    static class LZMADecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            byte propsByte = coder.properties[0];\n            long dictSize = coder.properties[1];\n            for (int i = 1; i < 4; i++) {\n", "suffix": "            }\n            if (dictSize > LZMAInputStream.DICT_SIZE_MAX) {\n                throw new IOException(\"Dictionary larger than 4GiB maximum size\");\n            }\n            return new LZMAInputStream(in, -1, propsByte, (int) dictSize);\n        }\n    }\n    \n    static class DeflateDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n            throws IOException {\n            return new InflaterInputStream(new DummyByteAddingInputStream(in),\n                                           new Inflater(true));\n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return new DeflaterOutputStream(out, new Deflater(9, true));\n        }\n    }\n\n    static class BZIP2Decoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n                throws IOException {\n            return new BZip2CompressorInputStream(in);\n", "buggy": "                byte[] password) throws IOException;\n        OutputStream encode(final OutputStream out, final byte[] password)\n            throws IOException {\n            throw new UnsupportedOperationException(\"method doesn't support writing\");\n        }\n    }\n    \n    static class CopyDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            return in; \n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return out;\n        }\n    }\n\n    static class LZMADecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            byte propsByte = coder.properties[0];\n            long dictSize = coder.properties[1];\n            for (int i = 1; i < 4; i++) {\n                dictSize |= (coder.properties[i + 1] << (8 * i));\n            }\n            if (dictSize > LZMAInputStream.DICT_SIZE_MAX) {\n                throw new IOException(\"Dictionary larger than 4GiB maximum size\");\n            }\n            return new LZMAInputStream(in, -1, propsByte, (int) dictSize);\n        }\n    }\n    \n    static class DeflateDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n            throws IOException {\n            return new InflaterInputStream(new DummyByteAddingInputStream(in),\n                                           new Inflater(true));\n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return new DeflaterOutputStream(out, new Deflater(9, true));\n        }\n    }\n\n    static class BZIP2Decoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n                throws IOException {\n            return new BZip2CompressorInputStream(in);\n", "fix": "                byte[] password) throws IOException;\n        OutputStream encode(final OutputStream out, final byte[] password)\n            throws IOException {\n            throw new UnsupportedOperationException(\"method doesn't support writing\");\n        }\n    }\n    \n    static class CopyDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            return in; \n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return out;\n        }\n    }\n\n    static class LZMADecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            byte propsByte = coder.properties[0];\n            long dictSize = coder.properties[1];\n            for (int i = 1; i < 4; i++) {\n                dictSize |= (coder.properties[i + 1] & 0xffl) << (8 * i);\n            }\n            if (dictSize > LZMAInputStream.DICT_SIZE_MAX) {\n                throw new IOException(\"Dictionary larger than 4GiB maximum size\");\n            }\n            return new LZMAInputStream(in, -1, propsByte, (int) dictSize);\n        }\n    }\n    \n    static class DeflateDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n            throws IOException {\n            return new InflaterInputStream(new DummyByteAddingInputStream(in),\n                                           new Inflater(true));\n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return new DeflaterOutputStream(out, new Deflater(9, true));\n        }\n    }\n\n    static class BZIP2Decoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n                throws IOException {\n            return new BZip2CompressorInputStream(in);\n", "start": 85, "end": 137, "file": "main/java/org/apache/commons/compress/archivers/sevenz/Coders.java"}], "Compress-25": [{"prefix": "     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding, boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields,\n                                 boolean allowStoredEntriesWithDataDescriptor) {\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n", "suffix": "    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n", "buggy": "     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding, boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields,\n                                 boolean allowStoredEntriesWithDataDescriptor) {\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n", "fix": "     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding, boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields,\n                                 boolean allowStoredEntriesWithDataDescriptor) {\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n", "start": 158, "end": 208, "file": "main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java"}], "Compress-38": [{"prefix": "     *\n     * @since 1.1\n     *\n     */\n    public boolean isPaxHeader(){\n        return linkFlag == LF_PAX_EXTENDED_HEADER_LC\n            || linkFlag == LF_PAX_EXTENDED_HEADER_UC;\n    }\n\n    /**\n     * Check if this is a Pax header.\n     *\n     * @return {@code true} if this is a Pax header.\n     *\n     * @since 1.1\n     */\n    public boolean isGlobalPaxHeader(){\n        return linkFlag == LF_PAX_GLOBAL_EXTENDED_HEADER;\n    }\n\n    /**\n     * Return whether or not this entry represents a directory.\n     *\n     * @return True if this entry is a directory.\n     */\n    @Override\n    public boolean isDirectory() {\n        if (file != null) {\n            return file.isDirectory();\n        }\n\n        if (linkFlag == LF_DIR) {\n            return true;\n        }\n\n", "suffix": "            return true;\n        }\n\n        return false;\n    }\n\n    /**\n     * Check if this is a \"normal file\"\n     *\n     * @since 1.2\n     * @return whether this is a \"normal file\"\n     */\n    public boolean isFile() {\n        if (file != null) {\n            return file.isFile();\n        }\n        if (linkFlag == LF_OLDNORM || linkFlag == LF_NORMAL) {\n            return true;\n        }\n        return !getName().endsWith(\"/\");\n    }\n\n    /**\n     * Check if this is a symbolic link entry.\n     *\n     * @since 1.2\n     * @return whether this is a symbolic link\n     */\n    public boolean isSymbolicLink() {\n        return linkFlag == LF_SYMLINK;\n    }\n\n    /**\n     * Check if this is a link entry.\n     *\n", "buggy": "     *\n     * @since 1.1\n     *\n     */\n    public boolean isPaxHeader(){\n        return linkFlag == LF_PAX_EXTENDED_HEADER_LC\n            || linkFlag == LF_PAX_EXTENDED_HEADER_UC;\n    }\n\n    /**\n     * Check if this is a Pax header.\n     *\n     * @return {@code true} if this is a Pax header.\n     *\n     * @since 1.1\n     */\n    public boolean isGlobalPaxHeader(){\n        return linkFlag == LF_PAX_GLOBAL_EXTENDED_HEADER;\n    }\n\n    /**\n     * Return whether or not this entry represents a directory.\n     *\n     * @return True if this entry is a directory.\n     */\n    @Override\n    public boolean isDirectory() {\n        if (file != null) {\n            return file.isDirectory();\n        }\n\n        if (linkFlag == LF_DIR) {\n            return true;\n        }\n\n        if (getName().endsWith(\"/\")) {\n            return true;\n        }\n\n        return false;\n    }\n\n    /**\n     * Check if this is a \"normal file\"\n     *\n     * @since 1.2\n     * @return whether this is a \"normal file\"\n     */\n    public boolean isFile() {\n        if (file != null) {\n            return file.isFile();\n        }\n        if (linkFlag == LF_OLDNORM || linkFlag == LF_NORMAL) {\n            return true;\n        }\n        return !getName().endsWith(\"/\");\n    }\n\n    /**\n     * Check if this is a symbolic link entry.\n     *\n     * @since 1.2\n     * @return whether this is a symbolic link\n     */\n    public boolean isSymbolicLink() {\n        return linkFlag == LF_SYMLINK;\n    }\n\n    /**\n     * Check if this is a link entry.\n     *\n", "fix": "     *\n     * @since 1.1\n     *\n     */\n    public boolean isPaxHeader(){\n        return linkFlag == LF_PAX_EXTENDED_HEADER_LC\n            || linkFlag == LF_PAX_EXTENDED_HEADER_UC;\n    }\n\n    /**\n     * Check if this is a Pax header.\n     *\n     * @return {@code true} if this is a Pax header.\n     *\n     * @since 1.1\n     */\n    public boolean isGlobalPaxHeader(){\n        return linkFlag == LF_PAX_GLOBAL_EXTENDED_HEADER;\n    }\n\n    /**\n     * Return whether or not this entry represents a directory.\n     *\n     * @return True if this entry is a directory.\n     */\n    @Override\n    public boolean isDirectory() {\n        if (file != null) {\n            return file.isDirectory();\n        }\n\n        if (linkFlag == LF_DIR) {\n            return true;\n        }\n\n        if (!isPaxHeader() && !isGlobalPaxHeader() && getName().endsWith(\"/\")) {\n            return true;\n        }\n\n        return false;\n    }\n\n    /**\n     * Check if this is a \"normal file\"\n     *\n     * @since 1.2\n     * @return whether this is a \"normal file\"\n     */\n    public boolean isFile() {\n        if (file != null) {\n            return file.isFile();\n        }\n        if (linkFlag == LF_OLDNORM || linkFlag == LF_NORMAL) {\n            return true;\n        }\n        return !getName().endsWith(\"/\");\n    }\n\n    /**\n     * Check if this is a symbolic link entry.\n     *\n     * @since 1.2\n     * @return whether this is a symbolic link\n     */\n    public boolean isSymbolicLink() {\n        return linkFlag == LF_SYMLINK;\n    }\n\n    /**\n     * Check if this is a link entry.\n     *\n", "start": 823, "end": 893, "file": "main/java/org/apache/commons/compress/archivers/tar/TarArchiveEntry.java"}], "Csv-1": [{"prefix": " * A special reader decorator which supports more\n * sophisticated access to the underlying reader object.\n *\n * In particular the reader supports a look-ahead option,\n * which allows you to see the next char returned by\n * next().\n */\nclass ExtendedBufferedReader extends BufferedReader {\n\n    /** The end of stream symbol */\n    static final int END_OF_STREAM = -1;\n\n    /** Undefined state for the lookahead char */\n    static final int UNDEFINED = -2;\n\n    /** The last char returned */\n    private int lastChar = UNDEFINED;\n\n    /** The line counter */\n    private int lineCounter = 0;\n\n    /**\n     * Created extended buffered reader using default buffer-size\n     */\n    ExtendedBufferedReader(Reader r) {\n        super(r);\n    }\n\n    @Override\n    public int read() throws IOException {\n        int current = super.read();\n", "suffix": "            lineCounter++;\n        }\n        lastChar = current;\n        return lastChar;\n    }\n\n    /**\n     * Returns the last character that was read as an integer (0 to 65535). This\n     * will be the last character returned by any of the read methods. This will\n     * not include a character read using the {@link #peek()} method. If no\n     * character has been read then this will return {@link #UNDEFINED}. If the\n     * end of the stream was reached on the last read then this will return\n     * {@link #END_OF_STREAM}.\n     * \n     * @return the last character that was read\n     */\n    int readAgain() {\n        return lastChar;\n    }\n\n    @Override\n    public int read(char[] buf, int offset, int length) throws IOException {\n        if (length == 0) {\n            return 0;\n        }\n        \n        int len = super.read(buf, offset, length);\n        \n        if (len > 0) {\n\n            for (int i = offset; i < offset + len; i++) {\n", "buggy": " * A special reader decorator which supports more\n * sophisticated access to the underlying reader object.\n *\n * In particular the reader supports a look-ahead option,\n * which allows you to see the next char returned by\n * next().\n */\nclass ExtendedBufferedReader extends BufferedReader {\n\n    /** The end of stream symbol */\n    static final int END_OF_STREAM = -1;\n\n    /** Undefined state for the lookahead char */\n    static final int UNDEFINED = -2;\n\n    /** The last char returned */\n    private int lastChar = UNDEFINED;\n\n    /** The line counter */\n    private int lineCounter = 0;\n\n    /**\n     * Created extended buffered reader using default buffer-size\n     */\n    ExtendedBufferedReader(Reader r) {\n        super(r);\n    }\n\n    @Override\n    public int read() throws IOException {\n        int current = super.read();\n        if (current == '\\n') {\n            lineCounter++;\n        }\n        lastChar = current;\n        return lastChar;\n    }\n\n    /**\n     * Returns the last character that was read as an integer (0 to 65535). This\n     * will be the last character returned by any of the read methods. This will\n     * not include a character read using the {@link #peek()} method. If no\n     * character has been read then this will return {@link #UNDEFINED}. If the\n     * end of the stream was reached on the last read then this will return\n     * {@link #END_OF_STREAM}.\n     * \n     * @return the last character that was read\n     */\n    int readAgain() {\n        return lastChar;\n    }\n\n    @Override\n    public int read(char[] buf, int offset, int length) throws IOException {\n        if (length == 0) {\n            return 0;\n        }\n        \n        int len = super.read(buf, offset, length);\n        \n        if (len > 0) {\n\n            for (int i = offset; i < offset + len; i++) {\n", "fix": " * A special reader decorator which supports more\n * sophisticated access to the underlying reader object.\n *\n * In particular the reader supports a look-ahead option,\n * which allows you to see the next char returned by\n * next().\n */\nclass ExtendedBufferedReader extends BufferedReader {\n\n    /** The end of stream symbol */\n    static final int END_OF_STREAM = -1;\n\n    /** Undefined state for the lookahead char */\n    static final int UNDEFINED = -2;\n\n    /** The last char returned */\n    private int lastChar = UNDEFINED;\n\n    /** The line counter */\n    private int lineCounter = 0;\n\n    /**\n     * Created extended buffered reader using default buffer-size\n     */\n    ExtendedBufferedReader(Reader r) {\n        super(r);\n    }\n\n    @Override\n    public int read() throws IOException {\n        int current = super.read();\n        if (current == '\\r' || (current == '\\n' && lastChar != '\\r')) {\n            lineCounter++;\n        }\n        lastChar = current;\n        return lastChar;\n    }\n\n    /**\n     * Returns the last character that was read as an integer (0 to 65535). This\n     * will be the last character returned by any of the read methods. This will\n     * not include a character read using the {@link #peek()} method. If no\n     * character has been read then this will return {@link #UNDEFINED}. If the\n     * end of the stream was reached on the last read then this will return\n     * {@link #END_OF_STREAM}.\n     * \n     * @return the last character that was read\n     */\n    int readAgain() {\n        return lastChar;\n    }\n\n    @Override\n    public int read(char[] buf, int offset, int length) throws IOException {\n        if (length == 0) {\n            return 0;\n        }\n        \n        int len = super.read(buf, offset, length);\n        \n        if (len > 0) {\n\n            for (int i = offset; i < offset + len; i++) {\n", "start": 26, "end": 88, "file": "main/java/org/apache/commons/csv/ExtendedBufferedReader.java"}], "Csv-4": [{"prefix": "     *             If an I/O error occurs\n     */\n    public void close() throws IOException {\n        if (this.lexer != null) {\n            this.lexer.close();\n        }\n    }\n\n    /**\n     * Returns the current line number in the input stream.\n     * <p/>\n     * ATTENTION: If your CSV input has multi-line values, the returned number does not correspond to the record number.\n     *\n     * @return current line number\n     */\n    public long getCurrentLineNumber() {\n        return this.lexer.getCurrentLineNumber();\n    }\n\n    /**\n     * Returns a copy of the header map that iterates in column order.\n     * <p>\n     * The map keys are column names. The map values are 0-based indices.\n     * </p>\n     * @return a copy of the header map that iterates in column order.\n     */\n    public Map<String, Integer> getHeaderMap() {\n", "suffix": "    }\n\n    /**\n     * Returns the current record number in the input stream.\n     * <p/>\n     * ATTENTION: If your CSV input has multi-line values, the returned number does not correspond to the line number.\n     *\n     * @return current line number\n     */\n    public long getRecordNumber() {\n        return this.recordNumber;\n    }\n\n    /**\n     * Parses the CSV input according to the given format and returns the content as a list of\n     * {@link CSVRecord CSVRecords}.\n     * <p/>\n     * The returned content starts at the current parse-position in the stream.\n     *\n     * @return list of {@link CSVRecord CSVRecords}, may be empty\n     * @throws IOException\n     *             on parse error or input read-failure\n     */\n    public List<CSVRecord> getRecords() throws IOException {\n        final List<CSVRecord> records = new ArrayList<CSVRecord>();\n        CSVRecord rec;\n        while ((rec = this.nextRecord()) != null) {\n", "buggy": "     *             If an I/O error occurs\n     */\n    public void close() throws IOException {\n        if (this.lexer != null) {\n            this.lexer.close();\n        }\n    }\n\n    /**\n     * Returns the current line number in the input stream.\n     * <p/>\n     * ATTENTION: If your CSV input has multi-line values, the returned number does not correspond to the record number.\n     *\n     * @return current line number\n     */\n    public long getCurrentLineNumber() {\n        return this.lexer.getCurrentLineNumber();\n    }\n\n    /**\n     * Returns a copy of the header map that iterates in column order.\n     * <p>\n     * The map keys are column names. The map values are 0-based indices.\n     * </p>\n     * @return a copy of the header map that iterates in column order.\n     */\n    public Map<String, Integer> getHeaderMap() {\n        return new LinkedHashMap<String, Integer>(this.headerMap);\n    }\n\n    /**\n     * Returns the current record number in the input stream.\n     * <p/>\n     * ATTENTION: If your CSV input has multi-line values, the returned number does not correspond to the line number.\n     *\n     * @return current line number\n     */\n    public long getRecordNumber() {\n        return this.recordNumber;\n    }\n\n    /**\n     * Parses the CSV input according to the given format and returns the content as a list of\n     * {@link CSVRecord CSVRecords}.\n     * <p/>\n     * The returned content starts at the current parse-position in the stream.\n     *\n     * @return list of {@link CSVRecord CSVRecords}, may be empty\n     * @throws IOException\n     *             on parse error or input read-failure\n     */\n    public List<CSVRecord> getRecords() throws IOException {\n        final List<CSVRecord> records = new ArrayList<CSVRecord>();\n        CSVRecord rec;\n        while ((rec = this.nextRecord()) != null) {\n", "fix": "     *             If an I/O error occurs\n     */\n    public void close() throws IOException {\n        if (this.lexer != null) {\n            this.lexer.close();\n        }\n    }\n\n    /**\n     * Returns the current line number in the input stream.\n     * <p/>\n     * ATTENTION: If your CSV input has multi-line values, the returned number does not correspond to the record number.\n     *\n     * @return current line number\n     */\n    public long getCurrentLineNumber() {\n        return this.lexer.getCurrentLineNumber();\n    }\n\n    /**\n     * Returns a copy of the header map that iterates in column order.\n     * <p>\n     * The map keys are column names. The map values are 0-based indices.\n     * </p>\n     * @return a copy of the header map that iterates in column order.\n     */\n    public Map<String, Integer> getHeaderMap() {\n        return this.headerMap == null ? null : new LinkedHashMap<String, Integer>(this.headerMap);\n    }\n\n    /**\n     * Returns the current record number in the input stream.\n     * <p/>\n     * ATTENTION: If your CSV input has multi-line values, the returned number does not correspond to the line number.\n     *\n     * @return current line number\n     */\n    public long getRecordNumber() {\n        return this.recordNumber;\n    }\n\n    /**\n     * Parses the CSV input according to the given format and returns the content as a list of\n     * {@link CSVRecord CSVRecords}.\n     * <p/>\n     * The returned content starts at the current parse-position in the stream.\n     *\n     * @return list of {@link CSVRecord CSVRecords}, may be empty\n     * @throws IOException\n     *             on parse error or input read-failure\n     */\n    public List<CSVRecord> getRecords() throws IOException {\n        final List<CSVRecord> records = new ArrayList<CSVRecord>();\n        CSVRecord rec;\n        while ((rec = this.nextRecord()) != null) {\n", "start": 260, "end": 314, "file": "main/java/org/apache/commons/csv/CSVParser.java"}], "Csv-11": [{"prefix": "     */\n    private Map<String, Integer> initializeHeader() throws IOException {\n        Map<String, Integer> hdrMap = null;\n        final String[] formatHeader = this.format.getHeader();\n        if (formatHeader != null) {\n            hdrMap = new LinkedHashMap<String, Integer>();\n\n            String[] headerRecord = null;\n            if (formatHeader.length == 0) {\n                // read the header from the first line of the file\n                final CSVRecord nextRecord = this.nextRecord();\n                if (nextRecord != null) {\n                    headerRecord = nextRecord.values();\n                }\n            } else {\n                if (this.format.getSkipHeaderRecord()) {\n                    this.nextRecord();\n                }\n                headerRecord = formatHeader;\n            }\n\n            // build the name to index mappings\n            if (headerRecord != null) {\n                for (int i = 0; i < headerRecord.length; i++) {\n                    final String header = headerRecord[i];\n                    final boolean containsHeader = hdrMap.containsKey(header);\n", "suffix": "                    if (containsHeader && (!emptyHeader || (emptyHeader && !this.format.getIgnoreEmptyHeaders()))) {\n                        throw new IllegalArgumentException(\"The header contains a duplicate name: \\\"\" + header +\n                                \"\\\" in \" + Arrays.toString(headerRecord));\n                    }\n                    hdrMap.put(header, Integer.valueOf(i));\n                }\n            }\n        }\n        return hdrMap;\n    }\n\n    public boolean isClosed() {\n        return this.lexer.isClosed();\n    }\n\n    /**\n     * Returns an iterator on the records.\n     *\n     * <p>IOExceptions occurring during the iteration are wrapped in a\n     * RuntimeException.\n     * If the parser is closed a call to {@code next()} will throw a\n     * NoSuchElementException.</p>\n     */\n    public Iterator<CSVRecord> iterator() {\n        return new Iterator<CSVRecord>() {\n            private CSVRecord current;\n", "buggy": "     */\n    private Map<String, Integer> initializeHeader() throws IOException {\n        Map<String, Integer> hdrMap = null;\n        final String[] formatHeader = this.format.getHeader();\n        if (formatHeader != null) {\n            hdrMap = new LinkedHashMap<String, Integer>();\n\n            String[] headerRecord = null;\n            if (formatHeader.length == 0) {\n                // read the header from the first line of the file\n                final CSVRecord nextRecord = this.nextRecord();\n                if (nextRecord != null) {\n                    headerRecord = nextRecord.values();\n                }\n            } else {\n                if (this.format.getSkipHeaderRecord()) {\n                    this.nextRecord();\n                }\n                headerRecord = formatHeader;\n            }\n\n            // build the name to index mappings\n            if (headerRecord != null) {\n                for (int i = 0; i < headerRecord.length; i++) {\n                    final String header = headerRecord[i];\n                    final boolean containsHeader = hdrMap.containsKey(header);\n                    final boolean emptyHeader = header.trim().isEmpty();\n                    if (containsHeader && (!emptyHeader || (emptyHeader && !this.format.getIgnoreEmptyHeaders()))) {\n                        throw new IllegalArgumentException(\"The header contains a duplicate name: \\\"\" + header +\n                                \"\\\" in \" + Arrays.toString(headerRecord));\n                    }\n                    hdrMap.put(header, Integer.valueOf(i));\n                }\n            }\n        }\n        return hdrMap;\n    }\n\n    public boolean isClosed() {\n        return this.lexer.isClosed();\n    }\n\n    /**\n     * Returns an iterator on the records.\n     *\n     * <p>IOExceptions occurring during the iteration are wrapped in a\n     * RuntimeException.\n     * If the parser is closed a call to {@code next()} will throw a\n     * NoSuchElementException.</p>\n     */\n    public Iterator<CSVRecord> iterator() {\n        return new Iterator<CSVRecord>() {\n            private CSVRecord current;\n", "fix": "     */\n    private Map<String, Integer> initializeHeader() throws IOException {\n        Map<String, Integer> hdrMap = null;\n        final String[] formatHeader = this.format.getHeader();\n        if (formatHeader != null) {\n            hdrMap = new LinkedHashMap<String, Integer>();\n\n            String[] headerRecord = null;\n            if (formatHeader.length == 0) {\n                // read the header from the first line of the file\n                final CSVRecord nextRecord = this.nextRecord();\n                if (nextRecord != null) {\n                    headerRecord = nextRecord.values();\n                }\n            } else {\n                if (this.format.getSkipHeaderRecord()) {\n                    this.nextRecord();\n                }\n                headerRecord = formatHeader;\n            }\n\n            // build the name to index mappings\n            if (headerRecord != null) {\n                for (int i = 0; i < headerRecord.length; i++) {\n                    final String header = headerRecord[i];\n                    final boolean containsHeader = hdrMap.containsKey(header);\n                    final boolean emptyHeader = header == null || header.trim().isEmpty();\n                    if (containsHeader && (!emptyHeader || (emptyHeader && !this.format.getIgnoreEmptyHeaders()))) {\n                        throw new IllegalArgumentException(\"The header contains a duplicate name: \\\"\" + header +\n                                \"\\\" in \" + Arrays.toString(headerRecord));\n                    }\n                    hdrMap.put(header, Integer.valueOf(i));\n                }\n            }\n        }\n        return hdrMap;\n    }\n\n    public boolean isClosed() {\n        return this.lexer.isClosed();\n    }\n\n    /**\n     * Returns an iterator on the records.\n     *\n     * <p>IOExceptions occurring during the iteration are wrapped in a\n     * RuntimeException.\n     * If the parser is closed a call to {@code next()} will throw a\n     * NoSuchElementException.</p>\n     */\n    public Iterator<CSVRecord> iterator() {\n        return new Iterator<CSVRecord>() {\n            private CSVRecord current;\n", "start": 357, "end": 409, "file": "main/java/org/apache/commons/csv/CSVParser.java"}], "Csv-14": [{"prefix": "        }\n        switch (quoteModePolicy) {\n        case ALL:\n            quote = true;\n            break;\n        case NON_NUMERIC:\n            quote = !(object instanceof Number);\n            break;\n        case NONE:\n            // Use the existing escaping code\n            printAndEscape(value, offset, len, out);\n            return;\n        case MINIMAL:\n            if (len <= 0) {\n                // always quote an empty token that is the first\n                // on the line, as it may be the only thing on the\n                // line. If it were not quoted in that case,\n                // an empty line has no tokens.\n                if (newRecord) {\n                    quote = true;\n                }\n            } else {\n                char c = value.charAt(pos);\n\n                // RFC4180 (https://tools.ietf.org/html/rfc4180) TEXTDATA =  %x20-21 / %x23-2B / %x2D-7E\n", "suffix": "                    quote = true;\n                } else if (c <= COMMENT) {\n                    // Some other chars at the start of a value caused the parser to fail, so for now\n                    // encapsulate if we start in anything less than '#'. We are being conservative\n                    // by including the default comment char too.\n                    quote = true;\n                } else {\n                    while (pos < end) {\n                        c = value.charAt(pos);\n                        if (c == LF || c == CR || c == quoteChar || c == delimChar) {\n                            quote = true;\n                            break;\n                        }\n                        pos++;\n                    }\n\n                    if (!quote) {\n                        pos = end - 1;\n                        c = value.charAt(pos);\n                        // Some other chars at the end caused the parser to fail, so for now\n                        // encapsulate if we end in anything less than ' '\n                        if (c <= SP) {\n                            quote = true;\n                        }\n                    }\n", "buggy": "        }\n        switch (quoteModePolicy) {\n        case ALL:\n            quote = true;\n            break;\n        case NON_NUMERIC:\n            quote = !(object instanceof Number);\n            break;\n        case NONE:\n            // Use the existing escaping code\n            printAndEscape(value, offset, len, out);\n            return;\n        case MINIMAL:\n            if (len <= 0) {\n                // always quote an empty token that is the first\n                // on the line, as it may be the only thing on the\n                // line. If it were not quoted in that case,\n                // an empty line has no tokens.\n                if (newRecord) {\n                    quote = true;\n                }\n            } else {\n                char c = value.charAt(pos);\n\n                // RFC4180 (https://tools.ietf.org/html/rfc4180) TEXTDATA =  %x20-21 / %x23-2B / %x2D-7E\n                if (newRecord && (c < '0' || c > '9' && c < 'A' || c > 'Z' && c < 'a' || c > 'z')) {\n                    quote = true;\n                } else if (c <= COMMENT) {\n                    // Some other chars at the start of a value caused the parser to fail, so for now\n                    // encapsulate if we start in anything less than '#'. We are being conservative\n                    // by including the default comment char too.\n                    quote = true;\n                } else {\n                    while (pos < end) {\n                        c = value.charAt(pos);\n                        if (c == LF || c == CR || c == quoteChar || c == delimChar) {\n                            quote = true;\n                            break;\n                        }\n                        pos++;\n                    }\n\n                    if (!quote) {\n                        pos = end - 1;\n                        c = value.charAt(pos);\n                        // Some other chars at the end caused the parser to fail, so for now\n                        // encapsulate if we end in anything less than ' '\n                        if (c <= SP) {\n                            quote = true;\n                        }\n                    }\n", "fix": "        }\n        switch (quoteModePolicy) {\n        case ALL:\n            quote = true;\n            break;\n        case NON_NUMERIC:\n            quote = !(object instanceof Number);\n            break;\n        case NONE:\n            // Use the existing escaping code\n            printAndEscape(value, offset, len, out);\n            return;\n        case MINIMAL:\n            if (len <= 0) {\n                // always quote an empty token that is the first\n                // on the line, as it may be the only thing on the\n                // line. If it were not quoted in that case,\n                // an empty line has no tokens.\n                if (newRecord) {\n                    quote = true;\n                }\n            } else {\n                char c = value.charAt(pos);\n\n                // RFC4180 (https://tools.ietf.org/html/rfc4180) TEXTDATA =  %x20-21 / %x23-2B / %x2D-7E\n                if (newRecord && (c < 0x20 || c > 0x21 && c < 0x23 || c > 0x2B && c < 0x2D || c > 0x7E)) {\n                    quote = true;\n                } else if (c <= COMMENT) {\n                    // Some other chars at the start of a value caused the parser to fail, so for now\n                    // encapsulate if we start in anything less than '#'. We are being conservative\n                    // by including the default comment char too.\n                    quote = true;\n                } else {\n                    while (pos < end) {\n                        c = value.charAt(pos);\n                        if (c == LF || c == CR || c == quoteChar || c == delimChar) {\n                            quote = true;\n                            break;\n                        }\n                        pos++;\n                    }\n\n                    if (!quote) {\n                        pos = end - 1;\n                        c = value.charAt(pos);\n                        // Some other chars at the end caused the parser to fail, so for now\n                        // encapsulate if we end in anything less than ' '\n                        if (c <= SP) {\n                            quote = true;\n                        }\n                    }\n", "start": 1013, "end": 1063, "file": "main/java/org/apache/commons/csv/CSVFormat.java"}], "Gson-5": [{"prefix": "                        }\n                    }\n                }\n            }\n\n            // extract timezone\n            if (date.length() <= offset) {\n                throw new IllegalArgumentException(\"No time zone indicator\");\n            }\n\n            TimeZone timezone = null;\n            char timezoneIndicator = date.charAt(offset);\n\n            if (timezoneIndicator == 'Z') {\n                timezone = TIMEZONE_UTC;\n                offset += 1;\n            } else if (timezoneIndicator == '+' || timezoneIndicator == '-') {\n                String timezoneOffset = date.substring(offset);\n\n                // When timezone has no minutes, we should append it, valid timezones are, for example: +00:00, +0000 and +00\n", "suffix": "\n                offset += timezoneOffset.length();\n                // 18-Jun-2015, tatu: Minor simplification, skip offset of \"+0000\"/\"+00:00\"\n                if (\"+0000\".equals(timezoneOffset) || \"+00:00\".equals(timezoneOffset)) {\n                    timezone = TIMEZONE_UTC;\n                } else {\n                    // 18-Jun-2015, tatu: Looks like offsets only work from GMT, not UTC...\n                    //    not sure why, but that's the way it looks. Further, Javadocs for\n                    //    `java.util.TimeZone` specifically instruct use of GMT as base for\n                    //    custom timezones... odd.\n                    String timezoneId = \"GMT\" + timezoneOffset;\n//                    String timezoneId = \"UTC\" + timezoneOffset;\n\n                    timezone = TimeZone.getTimeZone(timezoneId);\n\n                    String act = timezone.getID();\n                    if (!act.equals(timezoneId)) {\n                        /* 22-Jan-2015, tatu: Looks like canonical version has colons, but we may be given\n                         *    one without. If so, don't sweat.\n                         *   Yes, very inefficient. Hopefully not hit often.\n                         *   If it becomes a perf problem, add 'loose' comparison instead.\n", "buggy": "                        }\n                    }\n                }\n            }\n\n            // extract timezone\n            if (date.length() <= offset) {\n                throw new IllegalArgumentException(\"No time zone indicator\");\n            }\n\n            TimeZone timezone = null;\n            char timezoneIndicator = date.charAt(offset);\n\n            if (timezoneIndicator == 'Z') {\n                timezone = TIMEZONE_UTC;\n                offset += 1;\n            } else if (timezoneIndicator == '+' || timezoneIndicator == '-') {\n                String timezoneOffset = date.substring(offset);\n\n                // When timezone has no minutes, we should append it, valid timezones are, for example: +00:00, +0000 and +00\n\n                offset += timezoneOffset.length();\n                // 18-Jun-2015, tatu: Minor simplification, skip offset of \"+0000\"/\"+00:00\"\n                if (\"+0000\".equals(timezoneOffset) || \"+00:00\".equals(timezoneOffset)) {\n                    timezone = TIMEZONE_UTC;\n                } else {\n                    // 18-Jun-2015, tatu: Looks like offsets only work from GMT, not UTC...\n                    //    not sure why, but that's the way it looks. Further, Javadocs for\n                    //    `java.util.TimeZone` specifically instruct use of GMT as base for\n                    //    custom timezones... odd.\n                    String timezoneId = \"GMT\" + timezoneOffset;\n//                    String timezoneId = \"UTC\" + timezoneOffset;\n\n                    timezone = TimeZone.getTimeZone(timezoneId);\n\n                    String act = timezone.getID();\n                    if (!act.equals(timezoneId)) {\n                        /* 22-Jan-2015, tatu: Looks like canonical version has colons, but we may be given\n                         *    one without. If so, don't sweat.\n                         *   Yes, very inefficient. Hopefully not hit often.\n                         *   If it becomes a perf problem, add 'loose' comparison instead.\n", "fix": "                        }\n                    }\n                }\n            }\n\n            // extract timezone\n            if (date.length() <= offset) {\n                throw new IllegalArgumentException(\"No time zone indicator\");\n            }\n\n            TimeZone timezone = null;\n            char timezoneIndicator = date.charAt(offset);\n\n            if (timezoneIndicator == 'Z') {\n                timezone = TIMEZONE_UTC;\n                offset += 1;\n            } else if (timezoneIndicator == '+' || timezoneIndicator == '-') {\n                String timezoneOffset = date.substring(offset);\n\n                // When timezone has no minutes, we should append it, valid timezones are, for example: +00:00, +0000 and +00\n                timezoneOffset = timezoneOffset.length() >= 5 ? timezoneOffset : timezoneOffset + \"00\";\n\n                offset += timezoneOffset.length();\n                // 18-Jun-2015, tatu: Minor simplification, skip offset of \"+0000\"/\"+00:00\"\n                if (\"+0000\".equals(timezoneOffset) || \"+00:00\".equals(timezoneOffset)) {\n                    timezone = TIMEZONE_UTC;\n                } else {\n                    // 18-Jun-2015, tatu: Looks like offsets only work from GMT, not UTC...\n                    //    not sure why, but that's the way it looks. Further, Javadocs for\n                    //    `java.util.TimeZone` specifically instruct use of GMT as base for\n                    //    custom timezones... odd.\n                    String timezoneId = \"GMT\" + timezoneOffset;\n//                    String timezoneId = \"UTC\" + timezoneOffset;\n\n                    timezone = TimeZone.getTimeZone(timezoneId);\n\n                    String act = timezone.getID();\n                    if (!act.equals(timezoneId)) {\n                        /* 22-Jan-2015, tatu: Looks like canonical version has colons, but we may be given\n                         *    one without. If so, don't sweat.\n                         *   Yes, very inefficient. Hopefully not hit often.\n                         *   If it becomes a perf problem, add 'loose' comparison instead.\n", "start": 193, "end": 233, "file": "src/main/java/com/google/gson/internal/bind/util/ISO8601Utils.java"}], "Gson-11": [{"prefix": "    }\n  };\n\n  public static final TypeAdapter<Number> DOUBLE = new TypeAdapter<Number>() {\n    @Override\n    public Number read(JsonReader in) throws IOException {\n      if (in.peek() == JsonToken.NULL) {\n        in.nextNull();\n        return null;\n      }\n      return in.nextDouble();\n    }\n    @Override\n    public void write(JsonWriter out, Number value) throws IOException {\n      out.value(value);\n    }\n  };\n\n  public static final TypeAdapter<Number> NUMBER = new TypeAdapter<Number>() {\n    @Override\n    public Number read(JsonReader in) throws IOException {\n      JsonToken jsonToken = in.peek();\n      switch (jsonToken) {\n      case NULL:\n        in.nextNull();\n        return null;\n      case NUMBER:\n", "suffix": "        return new LazilyParsedNumber(in.nextString());\n      default:\n        throw new JsonSyntaxException(\"Expecting number, got: \" + jsonToken);\n      }\n    }\n    @Override\n    public void write(JsonWriter out, Number value) throws IOException {\n      out.value(value);\n    }\n  };\n\n  public static final TypeAdapterFactory NUMBER_FACTORY = newFactory(Number.class, NUMBER);\n\n  public static final TypeAdapter<Character> CHARACTER = new TypeAdapter<Character>() {\n    @Override\n    public Character read(JsonReader in) throws IOException {\n      if (in.peek() == JsonToken.NULL) {\n        in.nextNull();\n        return null;\n      }\n      String str = in.nextString();\n      if (str.length() != 1) {\n        throw new JsonSyntaxException(\"Expecting character, got: \" + str);\n      }\n      return str.charAt(0);\n    }\n    @Override\n    public void write(JsonWriter out, Character value) throws IOException {\n", "buggy": "    }\n  };\n\n  public static final TypeAdapter<Number> DOUBLE = new TypeAdapter<Number>() {\n    @Override\n    public Number read(JsonReader in) throws IOException {\n      if (in.peek() == JsonToken.NULL) {\n        in.nextNull();\n        return null;\n      }\n      return in.nextDouble();\n    }\n    @Override\n    public void write(JsonWriter out, Number value) throws IOException {\n      out.value(value);\n    }\n  };\n\n  public static final TypeAdapter<Number> NUMBER = new TypeAdapter<Number>() {\n    @Override\n    public Number read(JsonReader in) throws IOException {\n      JsonToken jsonToken = in.peek();\n      switch (jsonToken) {\n      case NULL:\n        in.nextNull();\n        return null;\n      case NUMBER:\n        return new LazilyParsedNumber(in.nextString());\n      default:\n        throw new JsonSyntaxException(\"Expecting number, got: \" + jsonToken);\n      }\n    }\n    @Override\n    public void write(JsonWriter out, Number value) throws IOException {\n      out.value(value);\n    }\n  };\n\n  public static final TypeAdapterFactory NUMBER_FACTORY = newFactory(Number.class, NUMBER);\n\n  public static final TypeAdapter<Character> CHARACTER = new TypeAdapter<Character>() {\n    @Override\n    public Character read(JsonReader in) throws IOException {\n      if (in.peek() == JsonToken.NULL) {\n        in.nextNull();\n        return null;\n      }\n      String str = in.nextString();\n      if (str.length() != 1) {\n        throw new JsonSyntaxException(\"Expecting character, got: \" + str);\n      }\n      return str.charAt(0);\n    }\n    @Override\n    public void write(JsonWriter out, Character value) throws IOException {\n", "fix": "    }\n  };\n\n  public static final TypeAdapter<Number> DOUBLE = new TypeAdapter<Number>() {\n    @Override\n    public Number read(JsonReader in) throws IOException {\n      if (in.peek() == JsonToken.NULL) {\n        in.nextNull();\n        return null;\n      }\n      return in.nextDouble();\n    }\n    @Override\n    public void write(JsonWriter out, Number value) throws IOException {\n      out.value(value);\n    }\n  };\n\n  public static final TypeAdapter<Number> NUMBER = new TypeAdapter<Number>() {\n    @Override\n    public Number read(JsonReader in) throws IOException {\n      JsonToken jsonToken = in.peek();\n      switch (jsonToken) {\n      case NULL:\n        in.nextNull();\n        return null;\n      case NUMBER:\n      case STRING:\n        return new LazilyParsedNumber(in.nextString());\n      default:\n        throw new JsonSyntaxException(\"Expecting number, got: \" + jsonToken);\n      }\n    }\n    @Override\n    public void write(JsonWriter out, Number value) throws IOException {\n      out.value(value);\n    }\n  };\n\n  public static final TypeAdapterFactory NUMBER_FACTORY = newFactory(Number.class, NUMBER);\n\n  public static final TypeAdapter<Character> CHARACTER = new TypeAdapter<Character>() {\n    @Override\n    public Character read(JsonReader in) throws IOException {\n      if (in.peek() == JsonToken.NULL) {\n        in.nextNull();\n        return null;\n      }\n      String str = in.nextString();\n      if (str.length() != 1) {\n        throw new JsonSyntaxException(\"Expecting character, got: \" + str);\n      }\n      return str.charAt(0);\n    }\n    @Override\n    public void write(JsonWriter out, Character value) throws IOException {\n", "start": 343, "end": 397, "file": "src/main/java/com/google/gson/internal/bind/TypeAdapters.java"}], "Gson-13": [{"prefix": "          }\n          return PEEKED_NONE;\n        }\n        if (last == NUMBER_CHAR_SIGN || last == NUMBER_CHAR_NONE) {\n          value = -(c - '0');\n          last = NUMBER_CHAR_DIGIT;\n        } else if (last == NUMBER_CHAR_DIGIT) {\n          if (value == 0) {\n            return PEEKED_NONE; // Leading '0' prefix is not allowed (since it could be octal).\n          }\n          long newValue = value * 10 - (c - '0');\n          fitsInLong &= value > MIN_INCOMPLETE_INTEGER\n              || (value == MIN_INCOMPLETE_INTEGER && newValue < value);\n          value = newValue;\n        } else if (last == NUMBER_CHAR_DECIMAL) {\n          last = NUMBER_CHAR_FRACTION_DIGIT;\n        } else if (last == NUMBER_CHAR_EXP_E || last == NUMBER_CHAR_EXP_SIGN) {\n          last = NUMBER_CHAR_EXP_DIGIT;\n        }\n      }\n    }\n\n    // We've read a complete number. Decide if it's a PEEKED_LONG or a PEEKED_NUMBER.\n", "suffix": "      peekedLong = negative ? value : -value;\n      pos += i;\n      return peeked = PEEKED_LONG;\n    } else if (last == NUMBER_CHAR_DIGIT || last == NUMBER_CHAR_FRACTION_DIGIT\n        || last == NUMBER_CHAR_EXP_DIGIT) {\n      peekedNumberLength = i;\n      return peeked = PEEKED_NUMBER;\n    } else {\n      return PEEKED_NONE;\n    }\n  }\n\n  private boolean isLiteral(char c) throws IOException {\n    switch (c) {\n    case '/':\n    case '\\\\':\n    case ';':\n    case '#':\n    case '=':\n      checkLenient(); // fall-through\n    case '{':\n    case '}':\n    case '[':\n", "buggy": "          }\n          return PEEKED_NONE;\n        }\n        if (last == NUMBER_CHAR_SIGN || last == NUMBER_CHAR_NONE) {\n          value = -(c - '0');\n          last = NUMBER_CHAR_DIGIT;\n        } else if (last == NUMBER_CHAR_DIGIT) {\n          if (value == 0) {\n            return PEEKED_NONE; // Leading '0' prefix is not allowed (since it could be octal).\n          }\n          long newValue = value * 10 - (c - '0');\n          fitsInLong &= value > MIN_INCOMPLETE_INTEGER\n              || (value == MIN_INCOMPLETE_INTEGER && newValue < value);\n          value = newValue;\n        } else if (last == NUMBER_CHAR_DECIMAL) {\n          last = NUMBER_CHAR_FRACTION_DIGIT;\n        } else if (last == NUMBER_CHAR_EXP_E || last == NUMBER_CHAR_EXP_SIGN) {\n          last = NUMBER_CHAR_EXP_DIGIT;\n        }\n      }\n    }\n\n    // We've read a complete number. Decide if it's a PEEKED_LONG or a PEEKED_NUMBER.\n    if (last == NUMBER_CHAR_DIGIT && fitsInLong && (value != Long.MIN_VALUE || negative)) {\n      peekedLong = negative ? value : -value;\n      pos += i;\n      return peeked = PEEKED_LONG;\n    } else if (last == NUMBER_CHAR_DIGIT || last == NUMBER_CHAR_FRACTION_DIGIT\n        || last == NUMBER_CHAR_EXP_DIGIT) {\n      peekedNumberLength = i;\n      return peeked = PEEKED_NUMBER;\n    } else {\n      return PEEKED_NONE;\n    }\n  }\n\n  private boolean isLiteral(char c) throws IOException {\n    switch (c) {\n    case '/':\n    case '\\\\':\n    case ';':\n    case '#':\n    case '=':\n      checkLenient(); // fall-through\n    case '{':\n    case '}':\n    case '[':\n", "fix": "          }\n          return PEEKED_NONE;\n        }\n        if (last == NUMBER_CHAR_SIGN || last == NUMBER_CHAR_NONE) {\n          value = -(c - '0');\n          last = NUMBER_CHAR_DIGIT;\n        } else if (last == NUMBER_CHAR_DIGIT) {\n          if (value == 0) {\n            return PEEKED_NONE; // Leading '0' prefix is not allowed (since it could be octal).\n          }\n          long newValue = value * 10 - (c - '0');\n          fitsInLong &= value > MIN_INCOMPLETE_INTEGER\n              || (value == MIN_INCOMPLETE_INTEGER && newValue < value);\n          value = newValue;\n        } else if (last == NUMBER_CHAR_DECIMAL) {\n          last = NUMBER_CHAR_FRACTION_DIGIT;\n        } else if (last == NUMBER_CHAR_EXP_E || last == NUMBER_CHAR_EXP_SIGN) {\n          last = NUMBER_CHAR_EXP_DIGIT;\n        }\n      }\n    }\n\n    // We've read a complete number. Decide if it's a PEEKED_LONG or a PEEKED_NUMBER.\n    if (last == NUMBER_CHAR_DIGIT && fitsInLong && (value != Long.MIN_VALUE || negative) && (value!=0 || false==negative)) {\n      peekedLong = negative ? value : -value;\n      pos += i;\n      return peeked = PEEKED_LONG;\n    } else if (last == NUMBER_CHAR_DIGIT || last == NUMBER_CHAR_FRACTION_DIGIT\n        || last == NUMBER_CHAR_EXP_DIGIT) {\n      peekedNumberLength = i;\n      return peeked = PEEKED_NUMBER;\n    } else {\n      return PEEKED_NONE;\n    }\n  }\n\n  private boolean isLiteral(char c) throws IOException {\n    switch (c) {\n    case '/':\n    case '\\\\':\n    case ';':\n    case '#':\n    case '=':\n      checkLenient(); // fall-through\n    case '{':\n    case '}':\n    case '[':\n", "start": 707, "end": 753, "file": "src/main/java/com/google/gson/stream/JsonReader.java"}], "Gson-15": [{"prefix": "   */\n  public JsonWriter value(boolean value) throws IOException {\n    writeDeferredName();\n    beforeValue();\n    out.write(value ? \"true\" : \"false\");\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @return this writer.\n   */\n  public JsonWriter value(Boolean value) throws IOException {\n    if (value == null) {\n      return nullValue();\n    }\n    writeDeferredName();\n    beforeValue();\n    out.write(value ? \"true\" : \"false\");\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n   *     {@link Double#isInfinite() infinities}.\n   * @return this writer.\n   */\n  public JsonWriter value(double value) throws IOException {\n    writeDeferredName();\n", "suffix": "      throw new IllegalArgumentException(\"Numeric values must be finite, but was \" + value);\n    }\n    beforeValue();\n    out.append(Double.toString(value));\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @return this writer.\n   */\n  public JsonWriter value(long value) throws IOException {\n    writeDeferredName();\n    beforeValue();\n    out.write(Long.toString(value));\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n   *     {@link Double#isInfinite() infinities}.\n   * @return this writer.\n   */\n  public JsonWriter value(Number value) throws IOException {\n    if (value == null) {\n      return nullValue();\n    }\n\n    writeDeferredName();\n", "buggy": "   */\n  public JsonWriter value(boolean value) throws IOException {\n    writeDeferredName();\n    beforeValue();\n    out.write(value ? \"true\" : \"false\");\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @return this writer.\n   */\n  public JsonWriter value(Boolean value) throws IOException {\n    if (value == null) {\n      return nullValue();\n    }\n    writeDeferredName();\n    beforeValue();\n    out.write(value ? \"true\" : \"false\");\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n   *     {@link Double#isInfinite() infinities}.\n   * @return this writer.\n   */\n  public JsonWriter value(double value) throws IOException {\n    writeDeferredName();\n    if (Double.isNaN(value) || Double.isInfinite(value)) {\n      throw new IllegalArgumentException(\"Numeric values must be finite, but was \" + value);\n    }\n    beforeValue();\n    out.append(Double.toString(value));\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @return this writer.\n   */\n  public JsonWriter value(long value) throws IOException {\n    writeDeferredName();\n    beforeValue();\n    out.write(Long.toString(value));\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n   *     {@link Double#isInfinite() infinities}.\n   * @return this writer.\n   */\n  public JsonWriter value(Number value) throws IOException {\n    if (value == null) {\n      return nullValue();\n    }\n\n    writeDeferredName();\n", "fix": "   */\n  public JsonWriter value(boolean value) throws IOException {\n    writeDeferredName();\n    beforeValue();\n    out.write(value ? \"true\" : \"false\");\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @return this writer.\n   */\n  public JsonWriter value(Boolean value) throws IOException {\n    if (value == null) {\n      return nullValue();\n    }\n    writeDeferredName();\n    beforeValue();\n    out.write(value ? \"true\" : \"false\");\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n   *     {@link Double#isInfinite() infinities}.\n   * @return this writer.\n   */\n  public JsonWriter value(double value) throws IOException {\n    writeDeferredName();\n    if (!lenient && (Double.isNaN(value) || Double.isInfinite(value))) {\n      throw new IllegalArgumentException(\"Numeric values must be finite, but was \" + value);\n    }\n    beforeValue();\n    out.append(Double.toString(value));\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @return this writer.\n   */\n  public JsonWriter value(long value) throws IOException {\n    writeDeferredName();\n    beforeValue();\n    out.write(Long.toString(value));\n    return this;\n  }\n\n  /**\n   * Encodes {@code value}.\n   *\n   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n   *     {@link Double#isInfinite() infinities}.\n   * @return this writer.\n   */\n  public JsonWriter value(Number value) throws IOException {\n    if (value == null) {\n      return nullValue();\n    }\n\n    writeDeferredName();\n", "start": 462, "end": 526, "file": "src/main/java/com/google/gson/stream/JsonWriter.java"}], "JacksonXml-5": [{"prefix": "    private static final long serialVersionUID = 1L;\n\n    /**\n     * If all we get to serialize is a null, there's no way to figure out\n     * expected root name; so let's just default to something like \"&lt;null>\"...\n     */\n    protected final static QName ROOT_NAME_FOR_NULL = new QName(\"null\");\n\n    protected final XmlRootNameLookup _rootNameLookup;\n\n    public XmlSerializerProvider(XmlRootNameLookup rootNames)\n    {\n        super();\n        _rootNameLookup = rootNames;\n    }\n\n    public XmlSerializerProvider(XmlSerializerProvider src,\n            SerializationConfig config, SerializerFactory f)\n    {\n        super(src, config, f);\n        _rootNameLookup  = src._rootNameLookup;\n    }\n\n    /**\n     * @since 2.8.9\n     */\n    protected XmlSerializerProvider(XmlSerializerProvider src) {\n        super(src);\n        // 21-May-2018, tatu: As per [dataformat-xml#282], should NOT really copy\n        //    root name lookup as that may link back to diff version, configuration\n", "suffix": "    }\n\n    /*\n    /**********************************************************************\n    /* Overridden methods\n    /**********************************************************************\n     */\n\n    @Override\n    public DefaultSerializerProvider copy() {\n        return new XmlSerializerProvider(this);\n    }\n\n    @Override\n    public DefaultSerializerProvider createInstance(SerializationConfig config,\n            SerializerFactory jsf) {\n        return new XmlSerializerProvider(this, config, jsf);\n    }\n\n    @SuppressWarnings(\"resource\")\n    @Override\n    public void serializeValue(JsonGenerator gen, Object value) throws IOException\n    {\n        if (value == null) {\n            _serializeXmlNull(gen);\n            return;\n        }\n        final Class<?> cls = value.getClass();\n        final boolean asArray;\n        final ToXmlGenerator xgen = _asXmlGenerator(gen);\n", "buggy": "    private static final long serialVersionUID = 1L;\n\n    /**\n     * If all we get to serialize is a null, there's no way to figure out\n     * expected root name; so let's just default to something like \"&lt;null>\"...\n     */\n    protected final static QName ROOT_NAME_FOR_NULL = new QName(\"null\");\n\n    protected final XmlRootNameLookup _rootNameLookup;\n\n    public XmlSerializerProvider(XmlRootNameLookup rootNames)\n    {\n        super();\n        _rootNameLookup = rootNames;\n    }\n\n    public XmlSerializerProvider(XmlSerializerProvider src,\n            SerializationConfig config, SerializerFactory f)\n    {\n        super(src, config, f);\n        _rootNameLookup  = src._rootNameLookup;\n    }\n\n    /**\n     * @since 2.8.9\n     */\n    protected XmlSerializerProvider(XmlSerializerProvider src) {\n        super(src);\n        // 21-May-2018, tatu: As per [dataformat-xml#282], should NOT really copy\n        //    root name lookup as that may link back to diff version, configuration\n        _rootNameLookup = src._rootNameLookup;\n    }\n\n    /*\n    /**********************************************************************\n    /* Overridden methods\n    /**********************************************************************\n     */\n\n    @Override\n    public DefaultSerializerProvider copy() {\n        return new XmlSerializerProvider(this);\n    }\n\n    @Override\n    public DefaultSerializerProvider createInstance(SerializationConfig config,\n            SerializerFactory jsf) {\n        return new XmlSerializerProvider(this, config, jsf);\n    }\n\n    @SuppressWarnings(\"resource\")\n    @Override\n    public void serializeValue(JsonGenerator gen, Object value) throws IOException\n    {\n        if (value == null) {\n            _serializeXmlNull(gen);\n            return;\n        }\n        final Class<?> cls = value.getClass();\n        final boolean asArray;\n        final ToXmlGenerator xgen = _asXmlGenerator(gen);\n", "fix": "    private static final long serialVersionUID = 1L;\n\n    /**\n     * If all we get to serialize is a null, there's no way to figure out\n     * expected root name; so let's just default to something like \"&lt;null>\"...\n     */\n    protected final static QName ROOT_NAME_FOR_NULL = new QName(\"null\");\n\n    protected final XmlRootNameLookup _rootNameLookup;\n\n    public XmlSerializerProvider(XmlRootNameLookup rootNames)\n    {\n        super();\n        _rootNameLookup = rootNames;\n    }\n\n    public XmlSerializerProvider(XmlSerializerProvider src,\n            SerializationConfig config, SerializerFactory f)\n    {\n        super(src, config, f);\n        _rootNameLookup  = src._rootNameLookup;\n    }\n\n    /**\n     * @since 2.8.9\n     */\n    protected XmlSerializerProvider(XmlSerializerProvider src) {\n        super(src);\n        // 21-May-2018, tatu: As per [dataformat-xml#282], should NOT really copy\n        //    root name lookup as that may link back to diff version, configuration\n        _rootNameLookup = new XmlRootNameLookup();\n    }\n\n    /*\n    /**********************************************************************\n    /* Overridden methods\n    /**********************************************************************\n     */\n\n    @Override\n    public DefaultSerializerProvider copy() {\n        return new XmlSerializerProvider(this);\n    }\n\n    @Override\n    public DefaultSerializerProvider createInstance(SerializationConfig config,\n            SerializerFactory jsf) {\n        return new XmlSerializerProvider(this, config, jsf);\n    }\n\n    @SuppressWarnings(\"resource\")\n    @Override\n    public void serializeValue(JsonGenerator gen, Object value) throws IOException\n    {\n        if (value == null) {\n            _serializeXmlNull(gen);\n            return;\n        }\n        final Class<?> cls = value.getClass();\n        final boolean asArray;\n        final ToXmlGenerator xgen = _asXmlGenerator(gen);\n", "start": 28, "end": 88, "file": "main/java/com/fasterxml/jackson/dataformat/xml/ser/XmlSerializerProvider.java"}], "JxPath-10": [{"prefix": " * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.jxpath.ri.compiler;\n\nimport java.util.Collection;\nimport java.util.HashSet;\nimport java.util.Iterator;\n\nimport org.apache.commons.jxpath.ri.EvalContext;\nimport org.apache.commons.jxpath.ri.InfoSetUtil;\nimport org.apache.commons.jxpath.ri.axes.InitialContext;\nimport org.apache.commons.jxpath.ri.axes.SelfContext;\n\n/**\n * Base implementation of Expression for the operations \"&gt;\", \"&gt;=\", \"&lt;\", \"&lt;=\".\n * @since JXPath 1.3\n *\n * @author Matt Benson\n * @version $Revision$ $Date$\n */\npublic abstract class CoreOperationRelationalExpression extends CoreOperation {\n\n    protected CoreOperationRelationalExpression(Expression[] args) {\n        super(args);\n    }\n\n    public final Object computeValue(EvalContext context) {\n", "suffix": "                ? Boolean.TRUE : Boolean.FALSE;\n    }\n\n    protected final int getPrecedence() {\n        return 3;\n    }\n\n    protected final boolean isSymmetric() {\n        return false;\n    }\n\n    protected abstract boolean evaluateCompare(int compare);\n\n    private boolean compute(Object left, Object right) {\n        left = reduce(left);\n        right = reduce(right);\n\n        if (left instanceof InitialContext) {\n            ((InitialContext) left).reset();\n        }\n        if (right instanceof InitialContext) {\n            ((InitialContext) right).reset();\n        }\n        if (left instanceof Iterator && right instanceof Iterator) {\n            return findMatch((Iterator) left, (Iterator) right);\n        }\n        if (left instanceof Iterator) {\n            return containsMatch((Iterator) left, right);\n", "buggy": " * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.jxpath.ri.compiler;\n\nimport java.util.Collection;\nimport java.util.HashSet;\nimport java.util.Iterator;\n\nimport org.apache.commons.jxpath.ri.EvalContext;\nimport org.apache.commons.jxpath.ri.InfoSetUtil;\nimport org.apache.commons.jxpath.ri.axes.InitialContext;\nimport org.apache.commons.jxpath.ri.axes.SelfContext;\n\n/**\n * Base implementation of Expression for the operations \"&gt;\", \"&gt;=\", \"&lt;\", \"&lt;=\".\n * @since JXPath 1.3\n *\n * @author Matt Benson\n * @version $Revision$ $Date$\n */\npublic abstract class CoreOperationRelationalExpression extends CoreOperation {\n\n    protected CoreOperationRelationalExpression(Expression[] args) {\n        super(args);\n    }\n\n    public final Object computeValue(EvalContext context) {\n        return compute(args[0].computeValue(context), args[1].computeValue(context)) \n                ? Boolean.TRUE : Boolean.FALSE;\n    }\n\n    protected final int getPrecedence() {\n        return 3;\n    }\n\n    protected final boolean isSymmetric() {\n        return false;\n    }\n\n    protected abstract boolean evaluateCompare(int compare);\n\n    private boolean compute(Object left, Object right) {\n        left = reduce(left);\n        right = reduce(right);\n\n        if (left instanceof InitialContext) {\n            ((InitialContext) left).reset();\n        }\n        if (right instanceof InitialContext) {\n            ((InitialContext) right).reset();\n        }\n        if (left instanceof Iterator && right instanceof Iterator) {\n            return findMatch((Iterator) left, (Iterator) right);\n        }\n        if (left instanceof Iterator) {\n            return containsMatch((Iterator) left, right);\n", "fix": " * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.jxpath.ri.compiler;\n\nimport java.util.Collection;\nimport java.util.HashSet;\nimport java.util.Iterator;\n\nimport org.apache.commons.jxpath.ri.EvalContext;\nimport org.apache.commons.jxpath.ri.InfoSetUtil;\nimport org.apache.commons.jxpath.ri.axes.InitialContext;\nimport org.apache.commons.jxpath.ri.axes.SelfContext;\n\n/**\n * Base implementation of Expression for the operations \"&gt;\", \"&gt;=\", \"&lt;\", \"&lt;=\".\n * @since JXPath 1.3\n *\n * @author Matt Benson\n * @version $Revision$ $Date$\n */\npublic abstract class CoreOperationRelationalExpression extends CoreOperation {\n\n    protected CoreOperationRelationalExpression(Expression[] args) {\n        super(args);\n    }\n\n    public final Object computeValue(EvalContext context) {\n        return compute(args[0].compute(context), args[1].compute(context))\n                ? Boolean.TRUE : Boolean.FALSE;\n    }\n\n    protected final int getPrecedence() {\n        return 3;\n    }\n\n    protected final boolean isSymmetric() {\n        return false;\n    }\n\n    protected abstract boolean evaluateCompare(int compare);\n\n    private boolean compute(Object left, Object right) {\n        left = reduce(left);\n        right = reduce(right);\n\n        if (left instanceof InitialContext) {\n            ((InitialContext) left).reset();\n        }\n        if (right instanceof InitialContext) {\n            ((InitialContext) right).reset();\n        }\n        if (left instanceof Iterator && right instanceof Iterator) {\n            return findMatch((Iterator) left, (Iterator) right);\n        }\n        if (left instanceof Iterator) {\n            return containsMatch((Iterator) left, right);\n", "start": 13, "end": 69, "file": "java/org/apache/commons/jxpath/ri/compiler/CoreOperationRelationalExpression.java"}]}